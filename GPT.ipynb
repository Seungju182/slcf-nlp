{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1cd1e4",
   "metadata": {},
   "source": [
    "### GPT\n",
    "GPT(Generated Pre-trained Transformer)는 트랜스포머의 디코더 구조를 활용한 pre-trained 언어모델이다. pre-trained 언어모델은 비지도 학습을 통해 문맥상 다음에 이어질 단어를 예측하는 모델이며, 자동완성 등의 분야에서 좋은 성능을 보였다. 모델 파라미터 수를 점차 늘림으로써 GPT-2, GPT-3까지 Open AI에서 공개한 상태."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600a338",
   "metadata": {},
   "source": [
    "#### BERT와의 차이점\n",
    "* BERT는 앞뒤 문맥을 살펴 학습하는 양방향 모델이고, GPT는 이전 문맥만을 가지고 다음 토큰을 맞추어야 하는 단방향 모델\n",
    "* BERT는 트랜스포머의 인코더(encoder)만, GPT는 트랜스포머의 **디코더(decoder)만** 취해 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6eab8",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21413715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "#import wget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acdcfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\\\Users\\\\user\\\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9700ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab loading\n",
    "vocab_file = f\"{data_dir}/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b3bae",
   "metadata": {},
   "source": [
    "모델에 설정값을 전달하기 위한 config를 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e292304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12c01997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
     ]
    }
   ],
   "source": [
    "config = Config({\n",
    "    \"n_dec_vocab\": len(vocab),\n",
    "    \"n_dec_seq\": 256,\n",
    "    \"n_layer\": 6,\n",
    "    \"d_hidn\": 256,\n",
    "    \"i_pad\": 0,\n",
    "    \"d_ff\": 1024,\n",
    "    \"n_head\": 4,\n",
    "    \"d_head\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"layer_norm_epsilon\": 1e-12\n",
    "})\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef4862",
   "metadata": {},
   "source": [
    "#### 공통으로 사용되는 여러 클래스 및 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c628d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" sinusoid position encoding \"\"\"\n",
    "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
    "    def cal_angle(position, i_hidn):\n",
    "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
    "\n",
    "    return sinusoid_table\n",
    "\n",
    "\n",
    "\"\"\" attention pad mask \"\"\"\n",
    "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
    "    return pad_attn_mask\n",
    "\n",
    "\n",
    "\"\"\" attention decoder mask \"\"\"\n",
    "def get_attn_decoder_mask(seq):\n",
    "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "\"\"\" scale dot product attention \"\"\"\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "        attn_prob = self.dropout(attn_prob)\n",
    "        # (bs, n_head, n_q_seq, d_v)\n",
    "        context = torch.matmul(attn_prob, V)\n",
    "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
    "        return context, attn_prob\n",
    "\n",
    "\n",
    "\"\"\" multi head attention \"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        batch_size = Q.size(0)\n",
    "        # (bs, n_head, n_q_seq, d_head)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_k_seq, d_head)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_v_seq, d_head)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
    "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
    "        # (bs, n_head, n_q_seq, e_embd)\n",
    "        output = self.linear(context)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        return output, attn_prob\n",
    "\n",
    "\n",
    "\"\"\" feed forward \"\"\"\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
    "        self.active = F.gelu\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # (bs, d_ff, n_seq)\n",
    "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0d361",
   "metadata": {},
   "source": [
    "#### decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3316c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "    \n",
    "    def forward(self, dec_inputs, self_attn_mask):\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
    "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
    "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
    "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        return ffn_outputs, self_attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b2a933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" decoder \"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
    "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, dec_inputs):\n",
    "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
    "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "    \n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
    "\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
    "\n",
    "        self_attn_probs = []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
    "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
    "            self_attn_probs.append(self_attn_prob)\n",
    "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)]\n",
    "        return dec_outputs, self_attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1c6e0",
   "metadata": {},
   "source": [
    "#### GPT model: 트랜스포머 디코더 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab91dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.decoder = Decoder(self.config)\n",
    "    \n",
    "    def forward(self, dec_inputs):\n",
    "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
    "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        return dec_outputs, dec_self_attn_probs\n",
    "    \n",
    "    def save(self, epoch, loss, path):\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss,\n",
    "            \"state_dict\": self.state_dict()\n",
    "        }, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        save = torch.load(path)\n",
    "        self.load_state_dict(save[\"state_dict\"])\n",
    "        return save[\"epoch\"], save[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5b49f",
   "metadata": {},
   "source": [
    "#### GPT pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "860535da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" GPT pretrain \"\"\"\n",
    "class GPTPretrain(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.gpt = GPT(self.config)\n",
    "        # lm\n",
    "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
    "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
    "    \n",
    "    def forward(self, dec_inputs):\n",
    "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
    "        # (bs, n_dec_seq, n_dec_vocab)\n",
    "        logits_lm = self.projection_lm(dec_outputs)\n",
    "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        return logits_lm[:, :-1, :].contiguous(), dec_self_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de6d85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" doc별 pretrain 데이터 생성 \"\"\"\n",
    "def create_pretrain_instances(doc, n_seq):\n",
    "    # for [BOS], [EOS]\n",
    "    max_seq = n_seq - 2\n",
    "    tgt_seq = max_seq\n",
    "    \n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i]) # line\n",
    "        current_length += len(doc[i])\n",
    "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
    "            if 0 < len(current_chunk):\n",
    "                tokens = []\n",
    "                for chunk in current_chunk: tokens.extend(chunk)\n",
    "                tokens = tokens[:tgt_seq]\n",
    "                if 1 < len(tokens):\n",
    "                    instance = {\n",
    "                        \"tokens\": [\"[BOS]\"] + tokens + [\"[EOS]\"],\n",
    "                    }\n",
    "                    instances.append(instance)\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "018b0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터 생성 \"\"\"\n",
    "def make_pretrain_data(vocab, in_file, out_file, n_seq):\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"rt\", encoding='UTF8') as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    docs = []\n",
    "    with open(in_file, \"rt\", encoding='UTF8') as f:\n",
    "        doc = []\n",
    "        with tqdm(total=line_cnt, desc=f\"Loading\") as pbar:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if line == \"\":\n",
    "                    if 0 < len(doc):\n",
    "                        docs.append(doc)\n",
    "                        doc = []\n",
    "                else:\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "                pbar.update(1)\n",
    "        if doc:\n",
    "            docs.append(doc)\n",
    "\n",
    "    with open(out_file, \"w\") as out_f:\n",
    "        with tqdm(total=len(docs), desc=f\"Making\") as pbar:\n",
    "            for i, doc in enumerate(docs):\n",
    "                instances = create_pretrain_instances(doc, n_seq)\n",
    "                for instance in instances:\n",
    "                    out_f.write(json.dumps(instance))\n",
    "                    out_f.write(\"\\n\")\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6b09be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|████████████████████████████████████████████| 3724301/3724301 [02:11<00:00, 28319.00it/s]\n",
      "Making: 100%|███████████████████████████████████████████████| 473912/473912 [00:23<00:00, 20172.69it/s]\n"
     ]
    }
   ],
   "source": [
    "in_file = f\"{data_dir}/kowiki.txt\"\n",
    "out_file = f\"{data_dir}/kowiki_gpt.json\"\n",
    "n_seq = 256\n",
    "\n",
    "if not os.path.isfile(out_file):\n",
    "    make_pretrain_data(vocab, in_file, out_file, n_seq)\n",
    "else:\n",
    "    print(f\"{out_file} exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0807a45",
   "metadata": {},
   "source": [
    "#### GPT pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60aef176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터셋 \"\"\"\n",
    "class PretrainDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.sentences = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        with open(infile, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "\n",
    "        with open(infile, \"r\") as f:\n",
    "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=\"Make Pretrain Dataset\", unit=\" lines\")):\n",
    "                instance = json.loads(line)\n",
    "                self.sentences.append([vocab.piece_to_id(p) for p in instance[\"tokens\"]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.sentences[item]), torch.tensor(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7ab4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain data collate_fn \"\"\"\n",
    "def pretrin_collate_fn(inputs):\n",
    "    dec_inputs, item = list(zip(*inputs))\n",
    "\n",
    "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
    "\n",
    "    batch = [\n",
    "        dec_inputs,\n",
    "        torch.stack(item, dim=0),\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc15b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Make Pretrain Dataset: 100%|█████████████████████████████| 769087/769087 [01:37<00:00, 7885.58 lines/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" pretrain 데이터 로더 \"\"\"\n",
    "batch_size = 128\n",
    "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_gpt.json\")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eaf19",
   "metadata": {},
   "source": [
    "#### PreTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92f7fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 모델 epoch 학습 \"\"\"\n",
    "def train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
    "        for i, value in enumerate(train_loader):\n",
    "            dec_inputs, _ = map(lambda v: v.to(config.device), value)\n",
    "            labels_lm = dec_inputs[:, 1:].contiguous()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(dec_inputs)\n",
    "            logits_lm = outputs[0]\n",
    "\n",
    "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
    "            loss = loss_lm \n",
    "\n",
    "            loss_val = loss_lm.item()\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef9e3b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(config)\n",
    "\n",
    "learning_rate = 5e-5\n",
    "n_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1acea4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                    | 0/20 [00:00<?, ?it/s]\n",
      "Train(0):   0%|                                                               | 0/6009 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch:   0%|                                                                    | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 8.00 GiB total capacity; 6.09 GiB already allocated; 0 bytes free; 6.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6620/2827893251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_lm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_pretrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6620/761167610.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(config, epoch, model, criterion_lm, optimizer, train_loader)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mlogits_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6620/2076552953.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dec_inputs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mdec_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_self_attn_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# (bs, n_dec_seq, n_dec_vocab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlogits_lm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojection_lm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6620/881446954.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dec_inputs)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdec_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_self_attn_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdec_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_self_attn_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6620/2567014311.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dec_inputs)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# (bs, n_dec_seq, d_hidn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mdec_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_inputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# (bs, n_dec_seq, n_dec_seq)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 8.00 GiB total capacity; 6.09 GiB already allocated; 0 bytes free; 6.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = GPTPretrain(config)\n",
    "\n",
    "save_pretrain = f\"{data_dir}/save_gpt_pretrain.pth\"\n",
    "best_epoch, best_loss = 0, 0\n",
    "if os.path.isfile(save_pretrain):\n",
    "    best_epoch, best_loss = model.gpt.load(save_pretrain)\n",
    "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
    "    best_epoch += 1\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "criterion_lm = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "offset = best_epoch\n",
    "for step in trange(n_epoch, desc=\"Epoch\"):\n",
    "    epoch = step + offset\n",
    "    loss = train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader)\n",
    "    losses.append(loss)\n",
    "    model.gpt.save(epoch, loss, save_pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef12d0",
   "metadata": {},
   "source": [
    "#### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83e439bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [loss]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data\n",
    "data = {\n",
    "    \"loss\": losses\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# graph\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
